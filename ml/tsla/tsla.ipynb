{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>728.650024</td>\n",
       "      <td>749.409973</td>\n",
       "      <td>724.599976</td>\n",
       "      <td>739.780029</td>\n",
       "      <td>739.780029</td>\n",
       "      <td>27979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>719.599976</td>\n",
       "      <td>725.400024</td>\n",
       "      <td>691.799988</td>\n",
       "      <td>714.630005</td>\n",
       "      <td>714.630005</td>\n",
       "      <td>39686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>717.419983</td>\n",
       "      <td>737.250000</td>\n",
       "      <td>710.690002</td>\n",
       "      <td>718.989990</td>\n",
       "      <td>718.989990</td>\n",
       "      <td>35609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>704.770020</td>\n",
       "      <td>744.840027</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>744.119995</td>\n",
       "      <td>744.119995</td>\n",
       "      <td>31215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>741.500000</td>\n",
       "      <td>753.770020</td>\n",
       "      <td>718.039978</td>\n",
       "      <td>719.690002</td>\n",
       "      <td>719.690002</td>\n",
       "      <td>35590300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2021-04-16  728.650024  749.409973  724.599976  739.780029  739.780029   \n",
       "1  2021-04-19  719.599976  725.400024  691.799988  714.630005  714.630005   \n",
       "2  2021-04-20  717.419983  737.250000  710.690002  718.989990  718.989990   \n",
       "3  2021-04-21  704.770020  744.840027  698.000000  744.119995  744.119995   \n",
       "4  2021-04-22  741.500000  753.770020  718.039978  719.690002  719.690002   \n",
       "\n",
       "     Volume  \n",
       "0  27979500  \n",
       "1  39686200  \n",
       "2  35609000  \n",
       "3  31215500  \n",
       "4  35590300  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv(\"TSLA.csv\")\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 728.650024]\n",
      " [ 719.599976]\n",
      " [ 717.419983]\n",
      " [ 704.77002 ]\n",
      " [ 741.5     ]\n",
      " [ 719.799988]\n",
      " [ 741.      ]\n",
      " [ 717.960022]\n",
      " [ 696.409973]\n",
      " [ 699.51001 ]\n",
      " [ 667.590027]\n",
      " [ 703.799988]\n",
      " [ 678.940002]\n",
      " [ 681.059998]\n",
      " [ 680.76001 ]\n",
      " [ 665.799988]\n",
      " [ 664.900024]\n",
      " [ 599.23999 ]\n",
      " [ 602.48999 ]\n",
      " [ 601.539978]\n",
      " [ 583.409973]\n",
      " [ 575.549988]\n",
      " [ 568.      ]\n",
      " [ 552.549988]\n",
      " [ 575.      ]\n",
      " [ 596.109985]\n",
      " [ 581.599976]\n",
      " [ 607.309998]\n",
      " [ 607.559998]\n",
      " [ 620.23999 ]\n",
      " [ 628.5     ]\n",
      " [ 627.799988]\n",
      " [ 620.130005]\n",
      " [ 601.799988]\n",
      " [ 579.710022]\n",
      " [ 591.830017]\n",
      " [ 623.01001 ]\n",
      " [ 602.169983]\n",
      " [ 603.880005]\n",
      " [ 610.22998 ]\n",
      " [ 612.22998 ]\n",
      " [ 616.690002]\n",
      " [ 597.539978]\n",
      " [ 601.890015]\n",
      " [ 613.369995]\n",
      " [ 624.47998 ]\n",
      " [ 618.25    ]\n",
      " [ 632.      ]\n",
      " [ 674.98999 ]\n",
      " [ 689.580017]\n",
      " [ 671.640015]\n",
      " [ 684.650024]\n",
      " [ 679.77002 ]\n",
      " [ 683.919983]\n",
      " [ 678.97998 ]\n",
      " [ 681.710022]\n",
      " [ 664.27002 ]\n",
      " [ 628.369995]\n",
      " [ 653.179993]\n",
      " [ 662.200012]\n",
      " [ 686.320007]\n",
      " [ 670.75    ]\n",
      " [ 658.390015]\n",
      " [ 654.679993]\n",
      " [ 629.890015]\n",
      " [ 651.98999 ]\n",
      " [ 659.609985]\n",
      " [ 656.440002]\n",
      " [ 646.359985]\n",
      " [ 650.969971]\n",
      " [ 663.400024]\n",
      " [ 647.      ]\n",
      " [ 649.789978]\n",
      " [ 671.76001 ]\n",
      " [ 700.      ]\n",
      " [ 719.      ]\n",
      " [ 711.      ]\n",
      " [ 716.      ]\n",
      " [ 711.900024]\n",
      " [ 710.169983]\n",
      " [ 713.98999 ]\n",
      " [ 712.710022]\n",
      " [ 706.340027]\n",
      " [ 723.710022]\n",
      " [ 705.070007]\n",
      " [ 672.659973]\n",
      " [ 669.75    ]\n",
      " [ 678.210022]\n",
      " [ 682.849976]\n",
      " [ 685.440002]\n",
      " [ 710.679993]\n",
      " [ 707.030029]\n",
      " [ 708.309998]\n",
      " [ 705.      ]\n",
      " [ 714.719971]\n",
      " [ 733.      ]\n",
      " [ 734.080017]\n",
      " [ 734.5     ]\n",
      " [ 732.25    ]\n",
      " [ 740.      ]\n",
      " [ 761.580017]\n",
      " [ 753.409973]\n",
      " [ 759.599976]\n",
      " [ 740.210022]\n",
      " [ 742.570007]\n",
      " [ 745.      ]\n",
      " [ 752.830017]\n",
      " [ 757.150024]\n",
      " [ 734.559998]\n",
      " [ 734.789978]\n",
      " [ 743.530029]\n",
      " [ 755.      ]\n",
      " [ 745.890015]\n",
      " [ 773.119995]\n",
      " [ 787.200012]\n",
      " [ 779.799988]\n",
      " [ 781.      ]\n",
      " [ 778.400024]\n",
      " [ 796.5     ]\n",
      " [ 784.799988]\n",
      " [ 776.200012]\n",
      " [ 785.460022]\n",
      " [ 796.210022]\n",
      " [ 787.650024]\n",
      " [ 800.929993]\n",
      " [ 810.469971]\n",
      " [ 815.48999 ]\n",
      " [ 823.73999 ]\n",
      " [ 851.789978]\n",
      " [ 877.530029]\n",
      " [ 865.349976]\n",
      " [ 856.      ]\n",
      " [ 895.5     ]\n",
      " [ 950.530029]\n",
      " [1024.689941]\n",
      " [1039.660034]\n",
      " [1068.310059]\n",
      " [1081.859985]\n",
      " [1145.      ]\n",
      " [1159.359985]\n",
      " [1177.329956]\n",
      " [1234.410034]\n",
      " [1228.      ]\n",
      " [1149.790039]\n",
      " [1173.599976]\n",
      " [1010.409973]\n",
      " [1102.77002 ]\n",
      " [1047.5     ]\n",
      " [1017.630005]\n",
      " [1003.309998]\n",
      " [1063.51001 ]\n",
      " [1106.550049]\n",
      " [1098.869995]\n",
      " [1162.329956]\n",
      " [1167.51001 ]\n",
      " [1080.390015]\n",
      " [1099.469971]\n",
      " [1100.98999 ]\n",
      " [1144.369995]\n",
      " [1160.699951]\n",
      " [1099.060059]\n",
      " [1084.790039]\n",
      " [1001.51001 ]\n",
      " [1044.199951]\n",
      " [1052.709961]\n",
      " [1060.640015]\n",
      " [1008.75    ]\n",
      " [1001.090027]\n",
      " [ 945.      ]\n",
      " [ 953.210022]\n",
      " [ 994.5     ]\n",
      " [ 914.77002 ]\n",
      " [ 910.700012]\n",
      " [ 916.869995]\n",
      " [ 965.659973]\n",
      " [1006.799988]\n",
      " [1073.670044]\n",
      " [1109.48999 ]\n",
      " [1098.640015]\n",
      " [1061.329956]\n",
      " [1073.439941]\n",
      " [1147.75    ]\n",
      " [1189.550049]\n",
      " [1146.650024]\n",
      " [1077.      ]\n",
      " [1080.369995]\n",
      " [1000.      ]\n",
      " [1053.670044]\n",
      " [1078.849976]\n",
      " [1109.069946]\n",
      " [1019.880005]\n",
      " [1026.609985]\n",
      " [1041.709961]\n",
      " [1009.72998 ]\n",
      " [ 996.340027]\n",
      " [ 904.76001 ]\n",
      " [ 914.200012]\n",
      " [ 952.429993]\n",
      " [ 933.359985]\n",
      " [ 831.559998]\n",
      " [ 872.710022]\n",
      " [ 935.210022]\n",
      " [ 928.179993]\n",
      " [ 882.      ]\n",
      " [ 897.219971]\n",
      " [ 923.789978]\n",
      " [ 905.530029]\n",
      " [ 935.      ]\n",
      " [ 908.369995]\n",
      " [ 909.630005]\n",
      " [ 861.570007]\n",
      " [ 900.      ]\n",
      " [ 914.049988]\n",
      " [ 913.26001 ]\n",
      " [ 886.      ]\n",
      " [ 834.130005]\n",
      " [ 830.429993]\n",
      " [ 700.390015]\n",
      " [ 809.22998 ]\n",
      " [ 815.01001 ]\n",
      " [ 869.679993]\n",
      " [ 872.130005]\n",
      " [ 878.77002 ]\n",
      " [ 849.099976]\n",
      " [ 856.299988]\n",
      " [ 795.530029]\n",
      " [ 839.47998 ]\n",
      " [ 851.450012]\n",
      " [ 840.200012]\n",
      " [ 780.609985]\n",
      " [ 775.27002 ]\n",
      " [ 809.      ]\n",
      " [ 830.98999 ]\n",
      " [ 874.48999 ]\n",
      " [ 914.97998 ]\n",
      " [ 930.      ]\n",
      " [ 979.940002]\n",
      " [1009.72998 ]\n",
      " [1008.      ]\n",
      " [1065.099976]\n",
      " [1107.98999 ]\n",
      " [1091.170044]\n",
      " [1094.569946]\n",
      " [1081.150024]\n",
      " [1089.380005]\n",
      " [1136.300049]\n",
      " [1073.469971]\n",
      " [1052.390015]\n",
      " [1043.209961]\n",
      " [ 980.400024]\n",
      " [ 997.640015]\n",
      " [ 981.080017]\n",
      " [ 999.289978]]\n",
      "(253, 1)\n"
     ]
    }
   ],
   "source": [
    "training_set = dataset_train.iloc[:,1:2].values\n",
    "print(training_set)\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2582642 ],\n",
       "       [0.24499161],\n",
       "       [0.24179448],\n",
       "       [0.22324234],\n",
       "       [0.27710967],\n",
       "       [0.24528494],\n",
       "       [0.27637638],\n",
       "       [0.24258649],\n",
       "       [0.21098169],\n",
       "       [0.21552813],\n",
       "       [0.16871503],\n",
       "       [0.22181971],\n",
       "       [0.18536064],\n",
       "       [0.18846978],\n",
       "       [0.18802982],\n",
       "       [0.1660898 ],\n",
       "       [0.16476994],\n",
       "       [0.06847447],\n",
       "       [0.07324084],\n",
       "       [0.07184757],\n",
       "       [0.04525853],\n",
       "       [0.03373126],\n",
       "       [0.02265863],\n",
       "       [0.        ],\n",
       "       [0.03292466],\n",
       "       [0.06388407],\n",
       "       [0.04260403],\n",
       "       [0.08030975],\n",
       "       [0.08067639],\n",
       "       [0.09927257],\n",
       "       [0.11138651],\n",
       "       [0.11035989],\n",
       "       [0.09911127],\n",
       "       [0.0722289 ],\n",
       "       [0.03983227],\n",
       "       [0.05760717],\n",
       "       [0.10333502],\n",
       "       [0.07277152],\n",
       "       [0.0752794 ],\n",
       "       [0.08459213],\n",
       "       [0.08752528],\n",
       "       [0.09406624],\n",
       "       [0.06598127],\n",
       "       [0.07236093],\n",
       "       [0.0891972 ],\n",
       "       [0.10549084],\n",
       "       [0.0963541 ],\n",
       "       [0.11651953],\n",
       "       [0.17956764],\n",
       "       [0.20096504],\n",
       "       [0.17465465],\n",
       "       [0.19373482],\n",
       "       [0.18657792],\n",
       "       [0.19266416],\n",
       "       [0.18541927],\n",
       "       [0.18942309],\n",
       "       [0.16384599],\n",
       "       [0.11119585],\n",
       "       [0.14758161],\n",
       "       [0.16081016],\n",
       "       [0.19618398],\n",
       "       [0.17334937],\n",
       "       [0.15522251],\n",
       "       [0.14978148],\n",
       "       [0.11342508],\n",
       "       [0.14583638],\n",
       "       [0.15701169],\n",
       "       [0.15236267],\n",
       "       [0.13757955],\n",
       "       [0.14434045],\n",
       "       [0.16257007],\n",
       "       [0.13851818],\n",
       "       [0.1426099 ],\n",
       "       [0.17483063],\n",
       "       [0.21624674],\n",
       "       [0.2441117 ],\n",
       "       [0.23237908],\n",
       "       [0.23971197],\n",
       "       [0.23369904],\n",
       "       [0.2311618 ],\n",
       "       [0.23676413],\n",
       "       [0.23488696],\n",
       "       [0.22554488],\n",
       "       [0.2510193 ],\n",
       "       [0.22368229],\n",
       "       [0.1761505 ],\n",
       "       [0.1718828 ],\n",
       "       [0.18429007],\n",
       "       [0.19109492],\n",
       "       [0.19489339],\n",
       "       [0.23190977],\n",
       "       [0.22655682],\n",
       "       [0.22843399],\n",
       "       [0.22357962],\n",
       "       [0.23783471],\n",
       "       [0.26464377],\n",
       "       [0.2662277 ],\n",
       "       [0.26684363],\n",
       "       [0.26354384],\n",
       "       [0.2749098 ],\n",
       "       [0.30655855],\n",
       "       [0.29457656],\n",
       "       [0.30365467],\n",
       "       [0.27521782],\n",
       "       [0.27867892],\n",
       "       [0.28224269],\n",
       "       [0.29372601],\n",
       "       [0.30006163],\n",
       "       [0.26693162],\n",
       "       [0.26726891],\n",
       "       [0.28008686],\n",
       "       [0.29690845],\n",
       "       [0.28354796],\n",
       "       [0.32348281],\n",
       "       [0.34413224],\n",
       "       [0.33327954],\n",
       "       [0.33503945],\n",
       "       [0.33122638],\n",
       "       [0.35777138],\n",
       "       [0.34061242],\n",
       "       [0.3279999 ],\n",
       "       [0.34158041],\n",
       "       [0.35734611],\n",
       "       [0.34479222],\n",
       "       [0.36426831],\n",
       "       [0.37825942],\n",
       "       [0.38562166],\n",
       "       [0.39772092],\n",
       "       [0.43885837],\n",
       "       [0.47660813],\n",
       "       [0.45874515],\n",
       "       [0.44503269],\n",
       "       [0.50296247],\n",
       "       [0.58366822],\n",
       "       [0.69242942],\n",
       "       [0.7143842 ],\n",
       "       [0.75640166],\n",
       "       [0.77627367],\n",
       "       [0.86887333],\n",
       "       [0.88993335],\n",
       "       [0.91628769],\n",
       "       [1.        ],\n",
       "       [0.99059919],\n",
       "       [0.87589829],\n",
       "       [0.91081739],\n",
       "       [0.67148675],\n",
       "       [0.80693983],\n",
       "       [0.72588211],\n",
       "       [0.68207548],\n",
       "       [0.66107409],\n",
       "       [0.74936202],\n",
       "       [0.81248354],\n",
       "       [0.80122015],\n",
       "       [0.89428904],\n",
       "       [0.90188599],\n",
       "       [0.77411784],\n",
       "       [0.80210006],\n",
       "       [0.80432928],\n",
       "       [0.86794938],\n",
       "       [0.89189852],\n",
       "       [0.80149889],\n",
       "       [0.78057081],\n",
       "       [0.65843427],\n",
       "       [0.72104234],\n",
       "       [0.73352292],\n",
       "       [0.74515295],\n",
       "       [0.66905227],\n",
       "       [0.65781833],\n",
       "       [0.57555801],\n",
       "       [0.58759864],\n",
       "       [0.64815355],\n",
       "       [0.53122343],\n",
       "       [0.52525445],\n",
       "       [0.5343032 ],\n",
       "       [0.60585744],\n",
       "       [0.66619243],\n",
       "       [0.76426249],\n",
       "       [0.81679518],\n",
       "       [0.80088286],\n",
       "       [0.7461648 ],\n",
       "       [0.76392503],\n",
       "       [0.87290642],\n",
       "       [0.93420939],\n",
       "       [0.87129322],\n",
       "       [0.76914612],\n",
       "       [0.77408848],\n",
       "       [0.65621973],\n",
       "       [0.73493096],\n",
       "       [0.77185926],\n",
       "       [0.81617916],\n",
       "       [0.68537528],\n",
       "       [0.69524531],\n",
       "       [0.71739058],\n",
       "       [0.67048949],\n",
       "       [0.65085209],\n",
       "       [0.51654298],\n",
       "       [0.53038747],\n",
       "       [0.58645467],\n",
       "       [0.55848704],\n",
       "       [0.40918956],\n",
       "       [0.46953922],\n",
       "       [0.56120026],\n",
       "       [0.55089018],\n",
       "       [0.48316368],\n",
       "       [0.50548494],\n",
       "       [0.54445189],\n",
       "       [0.51767227],\n",
       "       [0.56089225],\n",
       "       [0.5218373 ],\n",
       "       [0.5236852 ],\n",
       "       [0.45320153],\n",
       "       [0.50956206],\n",
       "       [0.53016745],\n",
       "       [0.52900888],\n",
       "       [0.48902999],\n",
       "       [0.41295867],\n",
       "       [0.40753232],\n",
       "       [0.21681873],\n",
       "       [0.37644087],\n",
       "       [0.38491773],\n",
       "       [0.46509545],\n",
       "       [0.46868858],\n",
       "       [0.47842667],\n",
       "       [0.43491328],\n",
       "       [0.44547265],\n",
       "       [0.35634885],\n",
       "       [0.42080482],\n",
       "       [0.43835979],\n",
       "       [0.4218608 ],\n",
       "       [0.33446746],\n",
       "       [0.32663599],\n",
       "       [0.37610359],\n",
       "       [0.4083536 ],\n",
       "       [0.47214968],\n",
       "       [0.53153135],\n",
       "       [0.55355936],\n",
       "       [0.6268002 ],\n",
       "       [0.67048949],\n",
       "       [0.66795234],\n",
       "       [0.75169383],\n",
       "       [0.81459532],\n",
       "       [0.78992758],\n",
       "       [0.7949138 ],\n",
       "       [0.77523245],\n",
       "       [0.78730235],\n",
       "       [0.85611419],\n",
       "       [0.76396907],\n",
       "       [0.7330537 ],\n",
       "       [0.71959044],\n",
       "       [0.62747486],\n",
       "       [0.65275863],\n",
       "       [0.62847212],\n",
       "       [0.65517842]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_training_set = scaler.fit_transform(training_set)\n",
    "\n",
    "scaled_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 60)\n",
      "(65,)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in  range(60, 125):\n",
    "    X_train.append(scaled_training_set[i-60:i,0])\n",
    "    y_train.append(scaled_training_set[i, 0])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 60, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 5s 92ms/step - loss: 0.0594\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0118\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0146\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0025\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0052\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0037\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0048\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0082\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0031\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0052\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0071\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0042\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0030\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0047\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0040\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0028\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0062\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0089\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0076\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0025\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0042\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0044\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0027\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0029\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0028\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0021\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0029\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0020\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0023\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0017\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0024\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0019\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0020\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0016\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0013\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0034\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0025\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0022\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0015\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0019\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0016\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0014\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0010\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0014\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0020\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0012\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0018\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0017\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0016\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0018\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0021\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0049\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0019\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0019\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0035\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0019\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0046\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0033\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0040\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0020\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0049\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0057\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0021\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0044\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0032\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0024\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0039\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0030\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0019\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0029\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0022\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0017\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0025\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0017\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0018\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0020\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0012\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0016\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0015\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0012\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0021\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0029\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0020\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0034\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0023\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0011\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0024\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0018\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0018\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0030\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0020\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0018\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0039\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0012\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0035\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0046\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7bd909820>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "regressor.fit(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jianbfan/opt/anaconda3/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 478, in change_attr_expression\n",
      "    value = eval(expression, frame.f_globals, frame.f_locals)\n",
      "  File \"<string>\", line 1\n",
      "    Date  Open  High  Low  Close  Adj Close  Volume0   4/15/22   NaN   NaN  NaN    NaN        NaN     NaN1   4/16/22   NaN   NaN  NaN    NaN        NaN     NaN2   4/17/22   NaN   NaN  NaN    NaN        NaN     NaN3   4/18/22   NaN   NaN  NaN    NaN        NaN     NaN4   4/19/22   NaN   NaN  NaN    NaN        NaN     NaN5   4/20/22   NaN   NaN  NaN    NaN        NaN     NaN6   4/21/22   NaN   NaN  NaN    NaN        NaN     NaN7   4/22/22   NaN   NaN  NaN    NaN        NaN     NaN8   4/23/22   NaN   NaN  NaN    NaN        NaN     NaN9   4/24/22   NaN   NaN  NaN    NaN        NaN     NaN10  4/25/22   NaN   NaN  NaN    NaN        NaN     NaN11  4/26/22   NaN   NaN  NaN    NaN        NaN     NaN12  4/27/22   NaN   NaN  NaN    NaN        NaN     NaN13  4/28/22   NaN   NaN  NaN    NaN        NaN     NaN14  4/29/22   NaN   NaN  NaN    NaN        NaN     NaN15  4/30/22   NaN   NaN  NaN    NaN        NaN     NaN16   5/1/22   NaN   NaN  NaN    NaN        NaN     NaN17   5/2/22   NaN   NaN  NaN    NaN        NaN     NaN18   5/3/22   NaN   NaN  NaN    NaN        NaN     NaN19   5/4/22   NaN   NaN  NaN    NaN        NaN     NaN20   5/5/22   NaN   NaN  NaN    NaN        NaN     NaN21   5/6/22   NaN   NaN  NaN    NaN        NaN     NaN22   5/7/22   NaN   NaN  NaN    NaN        NaN     NaN23   5/8/22   NaN   NaN  NaN    NaN        NaN     NaN24   5/9/22   NaN   NaN  NaN    NaN        NaN     NaN25  5/10/22   NaN   NaN  NaN    NaN        NaN     NaN26  5/11/22   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "          ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv(\"pred_tsla.csv\")\n",
    "\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_stock_prices = regressor.predict(X_test)\n",
    "Predicted_stock_prices = scaler.inverse_transform(Predicted_stock_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe7c06c7d00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Predicted_stock_prices, color = 'blue', label = 'Predicted tsla prices')\n",
    "plt.title('Tesla')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Telsa price')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dfbe5c73270b387ef522b74c69f79ee852b757b3d248966ea86475aa54b371c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
